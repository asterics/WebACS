<!doctype html>
<HTML>
<HEAD>
<meta charset="UTF-8">

<Title>Osc Gesture Follower</Title>
</HEAD>
<BODY>
<H1>Osc Gesture Follower</H1> 
<H3>Component Type: Processor (Subcategory: DSP and Feature Detection)</H3>
<p>The OscGestureFollower component copules the ARE with the external gesture recognition software GestureFollower. The program is copyrighted by IRCAM. GestureFollower is stored in the ARE subfolder tools/GestureFollower. 
Gesture data can be stored and loaded from files in this subdirectory, these files have the extension ".mubu". 
The communication between GestureFollower and the ARE is based on the OpenSoundControl (OSC) protocol. 
This plugin utilizes the NetUtil java library (http://www.sciss.de/netutil/) for the OSC implementation, 
it is (C)opyrighted 2004-2011 by Hanns Holger Rutz and released under the GNU Lesser General Public License. </p>
<div class="image"><img src="img/OscGestureFollower.jpg" alt="OscGestureFollower howto" title="OscGestureFollower howto" /><br>
OscGestureFollower howto</div>


<H2>Requirements</H2>
<ul>
<li>The plugin requires the gfOSC_v1.exe in subfolder tools/GestureFollower, which implements the actual gesture follower algorithms.</li>
<li>Check your firewall configuration and network settings to ensure that OSC messages are not blocked.  </li>
</ul>

<H2>Functional Principle</H2>
Input data is received through CH1 to CH4 e.g. from sensors like the acceleration measurement unit. Not all inputs must be connected, but the synchronized checkboxes have to be checked correct. 
The events must be connected like illustrated in the picture. First the gestures must be teached in. To teach in the first gesture, send an event into the 'learn1' eventListener. 
After finishing the first gesture, send an event to 'learn2' to teach in the second gesture, and so on. 
After all gestures are teached in, send the 'stoplearn' event. To clear all gestures send the 'clear' event. 
To start the gesture recognition process, send the 'follow' event. To stop the gesture following process, 
send the 'stop' event. The 'load' and 'save' events can be used to load or store the learned gesture data into the given filename. 
 
<H2>Input Port Description</H2>
<ul>
<li><STRONG>CH1 - CH4 [double]:</STRONG> The input port which receive data values. <b>These 4 input ports support synchronization</b>
</li>
</ul>

<H2>Output Port Description</H2>
<ul>
<li><STRONG>likeliest [double]:</STRONG> While the gesturefollower is in 'follwing mode' the most likeliest gesture is indicated on the likeliest output port. Before it can sample the input data and recognize a gesture, some data must be teached in.</li>
</ul>

<H2>Properties</H2>
<ul>
<li><STRONG>InPort [integer]:</STRONG> This value specifies the Port where OscMessages form the gesture follower are received.</li>
<li><STRONG>OutPort [integer]:</STRONG> This value specifies the Port where OscMessages are send to.</li>
<li><STRONG>filename [string]:</STRONG> Filename for the gesture data (load or save, .mubu file stored in the ARE subfoler tools/GestureFollower/). <b>Supports value suggestions from ARE (dynamic property)</b>.</li>
</ul>


<H2>Event Listener Ports</H2>
<ul>
<li><STRONG>stop:</STRONG> this event stops the gesture following</li>
<li><STRONG>stoplearn:</STRONG> this event stops the gesture learning process</li>
<li><STRONG>learn1 - learn5:</STRONG> these events select gestures 1 - 5 for learning</li>
<li><STRONG>learn1 - learn5:</STRONG> these events select gestures 1 - 5 for learning</li>
<li><STRONG>clear:</STRONG> this event clears learned gestures</li>
<li><STRONG>follow:</STRONG> this event starts the gesture recognition phase</li>
<li><STRONG>load:</STRONG> this event loads gesture data from file</li>
<li><STRONG>save:</STRONG> this event saves gesture data to file</li>
</ul>


<H2>Referred Plugins</H2>
<ul>
<li>OscOutClient </li>
<li>OpenVibe </li>
<li>OscServer </li>
</ul>


</ul>
</BODY>
</HTML>
